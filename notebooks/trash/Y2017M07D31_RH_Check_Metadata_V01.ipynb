{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check metadata\n",
    "\n",
    "* Purpose of script: check PCR-GlobWB metadata in a pure pythonic way\n",
    "* Author: Rutger Hofste\n",
    "* Kernel used: python27\n",
    "* Date created: 20170731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURPOSE\n",
    "\n",
    "    Read University of Utrecht files and store as geotiff\n",
    "    this project use a virtual environment with the following pip installs:\n",
    "    netcdf4, https://pythongisandstuff.wordpress.com/2016/04/13/installing-gdal-ogr-for-python-on-windows/\n",
    "\n",
    "## PROGRAMMER(S)\n",
    "    Rutger Hofste\n",
    "    Chris Slocum\n",
    "## REVISION HISTORY\n",
    "    20170203 -- GDAL part added\n",
    "    20161202 -- Rutger changes to work with UU data\n",
    "    20140320 -- Initial version created and posted online\n",
    "    20140722 -- Added basic error handling to ncdump\n",
    "                Thanks to K.-Michael Aye for highlighting the issue\n",
    "## REFERENCES\n",
    "    netcdf4-python -- http://code.google.com/p/netcdf4-python/\n",
    "    colormap -- http://matplotlib.org/examples/pylab_examples/custom_cmap.html\n",
    "    GDAL -- https://pythongisandstuff.wordpress.com/2016/04/13/installing-gdal-ogr-for-python-on-windows/\n",
    "\n",
    "## CAVEATS\n",
    "    I did not use a robust way to find the filename without extension. Filepath cannot contain periods. No error module built    in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from osgeo import ogr, osr, gdal\n",
    "except:\n",
    "    sys.exit('ERROR: cannot find GDAL/OGR modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdal.UseExceptions()\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NETCDFINPUTPATH = \"/volumes/data/PCRGlobWB20V01/\"\n",
    "PRINT_METADATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Definitions (functions) to the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ncdump(nc_fid, verb=True):\n",
    "    '''\n",
    "    ncdump outputs dimensions, variables and their attribute information.\n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_fid : netCDF4.Dataset\n",
    "        A netCDF4 dateset object\n",
    "    verb : Boolean\n",
    "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nc_attrs : list\n",
    "        A Python list of the NetCDF file global attributes\n",
    "    nc_dims : list\n",
    "        A Python list of the NetCDF file dimensions\n",
    "    nc_vars : list\n",
    "        A Python list of the NetCDF file variables\n",
    "    '''\n",
    "    def print_ncattr(key):\n",
    "        \"\"\"\n",
    "        Prints the NetCDF file attributes for a given key\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : unicode\n",
    "            a valid netCDF4.Dataset.variables key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print \"\\t\\ttype:\", repr(nc_fid.variables[key].dtype)\n",
    "            for ncattr in nc_fid.variables[key].ncattrs():\n",
    "                print '\\t\\t%s:' % ncattr,\\\n",
    "                      repr(nc_fid.variables[key].getncattr(ncattr))\n",
    "        except KeyError:\n",
    "            print \"\\t\\tWARNING: %s does not contain variable attributes\" % key\n",
    "            \n",
    "    # NetCDF global attributes\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    if verb:\n",
    "        print \"NetCDF Global Attributes:\"\n",
    "        for nc_attr in nc_attrs:\n",
    "            print '\\t%s:' % nc_attr, repr(nc_fid.getncattr(nc_attr))\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    # Dimension shape information.\n",
    "    if verb:\n",
    "        print \"NetCDF dimension information:\"\n",
    "        for dim in nc_dims:\n",
    "            print \"\\tName:\", dim\n",
    "            print \"\\t\\tsize:\", len(nc_fid.dimensions[dim])\n",
    "            print_ncattr(dim)\n",
    "    # Variable information.\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    if verb:\n",
    "        print \"NetCDF variable information:\"\n",
    "        for var in nc_vars:\n",
    "            if var not in nc_dims:\n",
    "                print '\\tName:', var\n",
    "                print \"\\t\\tdimensions:\", nc_fid.variables[var].dimensions\n",
    "                print \"\\t\\tsize:\", nc_fid.variables[var].size\n",
    "                print_ncattr(var)\n",
    "    return nc_attrs, nc_dims, nc_vars\n",
    "\n",
    "def normalizeTime(time):\n",
    "    timeNormal =[]\n",
    "    for i in range(0, len(time)):\n",
    "        if nc_fid.variables[\"time\"].getncattr(\"units\") == \"Days since 1900-01-01\":\n",
    "            fullDate = days_since_jan_1_1900_to_datetime(time[i])\n",
    "        elif nc_fid.variables[\"time\"].getncattr(\"units\") == \"days since 1900-01-01 00:00:00\":\n",
    "            fullDate = days_since_jan_1_1900_to_datetime(time[i])\n",
    "        elif nc_fid.variables[\"time\"].getncattr(\"units\") == \"Days since 1901-01-01\":\n",
    "            fullDate = days_since_jan_1_1901_to_datetime(time[i])\n",
    "        else:\n",
    "            print \"Error\"\n",
    "            print(nc_fid.variables[\"time\"].getncattr(\"units\"))\n",
    "        fullDate = days_since_jan_1_1900_to_datetime(time[i])\n",
    "        timeNormal.append(fullDate)\n",
    "    return timeNormal\n",
    "\n",
    "def days_since_jan_1_1900_to_datetime(d):\n",
    "    return datetime.datetime(1900,1,1) + datetime.timedelta(days=d)\n",
    "\n",
    "def days_since_jan_1_1901_to_datetime(d):\n",
    "    return datetime.datetime(1901,1,1) + datetime.timedelta(days=d)\n",
    "\n",
    "def printMetaData(oneFile):\n",
    "    netCDFInputFileName = oneFile\n",
    "    print oneFile\n",
    "    netCDFInputBaseName = netCDFInputFileName.split('.')[0]\n",
    "    nc_f = oneFile\n",
    "    nc_fid = Dataset(nc_f, 'r')  # Dataset is the class behavior to open the file\n",
    "         # and create an instance of the ncCDF4 class\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_fid, PRINT_METADATA)\n",
    "    parameter = nc_vars[3]\n",
    "\n",
    "    lats = nc_fid.variables['latitude'][:]  # extract/copy the data\n",
    "    lons = nc_fid.variables['longitude'][:]\n",
    "    time = nc_fid.variables['time'][:]\n",
    "    timeNormal = normalizeTime(time)\n",
    "\n",
    "    #print \"Time Minimum: \", min(timeNormal), \"Days since start (1901 or 1900)\", min(time)\n",
    "    #print \"Time Maximum: \", max(timeNormal), \"Days since start (1901 or 1900)\", max(time)\n",
    "    #print \"Number of layers\", len(timeNormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/volumes/data/PCRGlobWB20V01/global_historical_PIrrWW_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/global_historical_PIrrWW_month_millionm3_5min_1960_2014.nc4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'nc_fid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f9a4a9865af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0moneFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mprintMetaData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moneFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5849e3444849>\u001b[0m in \u001b[0;36mprintMetaData\u001b[0;34m(oneFile)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mlons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc_fid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc_fid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtimeNormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizeTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m#print \"Time Minimum: \", min(timeNormal), \"Days since start (1901 or 1900)\", min(time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-5849e3444849>\u001b[0m in \u001b[0;36mnormalizeTime\u001b[0;34m(time)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtimeNormal\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnc_fid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetncattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"units\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Days since 1900-01-01\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mfullDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdays_since_jan_1_1900_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnc_fid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetncattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"units\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"days since 1900-01-01 00:00:00\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'nc_fid' is not defined"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(NETCDFINPUTPATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".nc4\"):\n",
    "            oneFile = os.path.join(root, file)\n",
    "            print(oneFile)\n",
    "            printMetaData(oneFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_f = oneFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nc_fid = Dataset(nc_f, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"number of files: \" +str(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this script was used to check the metadata. The results were copied to a texteditor and inpected. The results are not saved to disk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the maximum extend of the data to check the NetCDF4 CRS: \n",
    "\n",
    "Latitudes and Longitudes are postings meaning they represent the center of a cell and not the edge. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print min(lats) , max(lats), min(lons), max(lons)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(lats)\n",
    "print len(lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellsize = 360.0/(len(lons))\n",
    "cellsize2 = 180.0/(len(lats))\n",
    "print cellsize, cellsize2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLat = max(lats)+0.5*cellsize\n",
    "minLat = min(lats)-0.5*cellsize\n",
    "\n",
    "maxLon = max(lons)+0.5*cellsize\n",
    "minLon = min(lons)-0.5*cellsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extent has a slight error, caused by the rounding error of the cellsize. This is due to the fact that the model uses 5 arc minute resolution and not a rational number. When creating a reference geotiff, you therefore make a slight error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print maxLat, maxLon\n",
    "print minLat, minLon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is not significant. For the development of Aqueduct we used a standard geometry and coordinate reference system (CRS). The standard geotiff can be found in our Amazon Bucket:\n",
    "\n",
    "`wri-projects/Aqueduct30/rawData/WRI/samplegeotiff`\n",
    "\n",
    "ArcGIS has a limited precision when storing CRS and the extent translates to (copied from ArcGIS/QGIS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLatArc =  090.0000025443094\n",
    "minLatArc = -089.9999923682499\n",
    "\n",
    "minLonArc = -179.999994912559\n",
    "maxLonArc =  179.999994912559\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yield a maximum error of (Degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = [maxLat-maxLatArc,minLat-minLatArc,maxLon-maxLonArc,minLon-minLonArc]\n",
    "\n",
    "def absolute(x): \n",
    "    return abs(x)\n",
    "\n",
    "absErrors = map(absolute,errors)\n",
    "maxError = max(absErrors)\n",
    "WGS84r = 6378137\n",
    "circumference = math.pi*WGS84r*2\n",
    "maxErrorm = maxError * (circumference/360)\n",
    "print \"Maximum error in m: \" + str(maxErrorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is acceptable given the cell size is 5min or ~9.3km at the equator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 27",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
