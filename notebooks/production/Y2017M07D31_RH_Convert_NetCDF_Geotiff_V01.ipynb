{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check metadata\n",
    "\n",
    "* Purpose of script: This notebook will transform netCDF to geotiff.  \n",
    "* Author: Rutger Hofste\n",
    "* Kernel used: python27\n",
    "* Date created: 20170731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "as explained in the previous step, we need to put the NetCDF data into a coordinate reference system. For that we use a standard geometry. \n",
    "\n",
    "Download the standard geotiff to our instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command just in case an old folder exists. _If no older folder exist you will get the error: rm: cannot remove '/volumes/data/PCRGlobWB20V01/additional/*': No such file or directory_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /volumes/data/PCRGlobWB20V01/additional/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff/readme.txt to ../../../../data/PCRGlobWB20V01/additional/readme.txt\n",
      "download: s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff/sampleGeotiff.tiff to ../../../../data/PCRGlobWB20V01/additional/sampleGeotiff.tiff\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync s3://wri-projects/Aqueduct30/rawData/WRI/samplegeotiff/ /volumes/data/PCRGlobWB20V01/additional/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the file is actually copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -r /volumes/data/temp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir /volumes/data/temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme.txt  sampleGeotiff.tiff\r\n"
     ]
    }
   ],
   "source": [
    "!ls /volumes/data/PCRGlobWB20V01/additional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from osgeo import ogr, osr, gdal\n",
    "except:\n",
    "    sys.exit('ERROR: cannot find GDAL/OGR modules')\n",
    "    \n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import datetime\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    filehandle = gdal.Open(filename)\n",
    "    band1 = filehandle.GetRasterBand(1)\n",
    "    geotransform = filehandle.GetGeoTransform()\n",
    "    geoproj = filehandle.GetProjection()\n",
    "    Z = band1.ReadAsArray()\n",
    "    xsize = filehandle.RasterXSize\n",
    "    ysize = filehandle.RasterYSize\n",
    "    filehandle = None\n",
    "    return xsize,ysize,geotransform,geoproj,Z\n",
    "\n",
    "def writeFile(filename,geotransform,geoprojection,data):\n",
    "    (x,y) = data.shape\n",
    "    format = \"GTiff\"\n",
    "    driver = gdal.GetDriverByName(format)\n",
    "    # you can change the dataformat but be sure to be able to store negative values including -9999\n",
    "    dst_datatype = gdal.GDT_Float32\n",
    "    dst_ds = driver.Create(filename,y,x,1,dst_datatype, [ 'COMPRESS=LZW' ])\n",
    "    dst_ds.GetRasterBand(1).SetNoDataValue(-9999)\n",
    "    dst_ds.GetRasterBand(1).WriteArray(data)\n",
    "    dst_ds.SetGeoTransform(geotransform)\n",
    "    dst_ds.SetProjection(geoprojection)\n",
    "    dst_ds = None\n",
    "    return 1\n",
    "\n",
    "def ncdump(nc_fid, verb=True):\n",
    "    '''\n",
    "    ncdump outputs dimensions, variables and their attribute information.\n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_fid : netCDF4.Dataset\n",
    "        A netCDF4 dateset object\n",
    "    verb : Boolean\n",
    "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nc_attrs : list\n",
    "        A Python list of the NetCDF file global attributes\n",
    "    nc_dims : list\n",
    "        A Python list of the NetCDF file dimensions\n",
    "    nc_vars : list\n",
    "        A Python list of the NetCDF file variables\n",
    "    '''\n",
    "    def print_ncattr(key):\n",
    "        \"\"\"\n",
    "        Prints the NetCDF file attributes for a given key\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : unicode\n",
    "            a valid netCDF4.Dataset.variables key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print \"\\t\\ttype:\", repr(nc_fid.variables[key].dtype)\n",
    "            for ncattr in nc_fid.variables[key].ncattrs():\n",
    "                print '\\t\\t%s:' % ncattr,\\\n",
    "                      repr(nc_fid.variables[key].getncattr(ncattr))\n",
    "        except KeyError:\n",
    "            print \"\\t\\tWARNING: %s does not contain variable attributes\" % key\n",
    "\n",
    "    # NetCDF global attributes\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    if verb:\n",
    "        print \"NetCDF Global Attributes:\"\n",
    "        for nc_attr in nc_attrs:\n",
    "            print '\\t%s:' % nc_attr, repr(nc_fid.getncattr(nc_attr))\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    # Dimension shape information.\n",
    "    if verb:\n",
    "        print \"NetCDF dimension information:\"\n",
    "        for dim in nc_dims:\n",
    "            print \"\\tName:\", dim\n",
    "            print \"\\t\\tsize:\", len(nc_fid.dimensions[dim])\n",
    "            print_ncattr(dim)\n",
    "    # Variable information.\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    if verb:\n",
    "        print \"NetCDF variable information:\"\n",
    "        for var in nc_vars:\n",
    "            if var not in nc_dims:\n",
    "                print '\\tName:', var\n",
    "                print \"\\t\\tdimensions:\", nc_fid.variables[var].dimensions\n",
    "                print \"\\t\\tsize:\", nc_fid.variables[var].size\n",
    "                print_ncattr(var)\n",
    "    return nc_attrs, nc_dims, nc_vars\n",
    "\n",
    "def normalizeTime(time):\n",
    "    timeNormal =[]\n",
    "    for i in range(0, len(time)):\n",
    "        if nc_fid.variables[\"time\"].getncattr(\"units\") == \"Days since 1900-01-01\":\n",
    "            fullDate = days_since_jan_1_1900_to_datetime(time[i])\n",
    "        elif nc_fid.variables[\"time\"].getncattr(\"units\") == \"Days since 1901-01-01\":\n",
    "            fullDate = days_since_jan_1_1901_to_datetime(time[i])\n",
    "        else:\n",
    "            print \"Error\"\n",
    "        fullDate = days_since_jan_1_1900_to_datetime(time[i])\n",
    "        timeNormal.append(fullDate)\n",
    "    return timeNormal\n",
    "\n",
    "def days_since_jan_1_1900_to_datetime(d):\n",
    "    return datetime.datetime(1900,1,1) + datetime.timedelta(days=d)\n",
    "\n",
    "def days_since_jan_1_1901_to_datetime(d):\n",
    "    return datetime.datetime(1901,1,1) + datetime.timedelta(days=d)\n",
    "\n",
    "def print_ncattr(key):\n",
    "    \"\"\"\n",
    "    Prints the NetCDF file attributes for a given key\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : unicode\n",
    "        a valid netCDF4.Dataset.variables key\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print \"\\t\\ttype:\", repr(nc_fid.variables[key].dtype)\n",
    "        for ncattr in nc_fid.variables[key].ncattrs():\n",
    "            print '\\t\\t%s:' % ncattr,\\\n",
    "                  repr(nc_fid.variables[key].getncattr(ncattr))\n",
    "    except KeyError:\n",
    "        print \"\\t\\tWARNING: %s does not contain variable attributes\" % key\n",
    "        \n",
    "def netCDFtoGeotiff(oneFile):\n",
    "    netCDFInputFileName = oneFile\n",
    "    print(oneFile)\n",
    "    netCDFInputBaseName = netCDFInputFileName.split('.')[0]\n",
    "\n",
    "    nc_f = os.path.join(NETCDFINPUTPATH,netCDFInputFileName)\n",
    "    nc_fid = Dataset(nc_f, 'r')  # Dataset is the class behavior to open the file\n",
    "         # and create an instance of the ncCDF4 class\n",
    "    nc_attrs, nc_dims, nc_vars = ncdump(nc_fid, PRINT_METADATA)\n",
    "    parameter = nc_vars[3]\n",
    "\n",
    "    lats = nc_fid.variables['latitude'][:]  # extract/copy the data\n",
    "    lons = nc_fid.variables['longitude'][:]\n",
    "    time = nc_fid.variables['time'][:]\n",
    "    timeNormal = normalizeTime(time)\n",
    "    \n",
    "    for i in range(0,len(timeNormal)):\n",
    "        print timeNormal[i].year\n",
    "        Z = nc_fid.variables[parameter][i, :, :]\n",
    "        Z[Z<-9990]= -9999\n",
    "        Z[Z>1e19] = -9999\n",
    "        outputFilename = netCDFInputBaseName + \"I%0.3dY%0.2dM%0.2d.tif\" %(i,timeNormal[i].year,timeNormal[i].month)\n",
    "        writefilename = os.path.join(OUTPUTPATH,outputFilename)\n",
    "        writeFile(writefilename,geotransform,geoproj,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NETCDFINPUTPATH = \"/volumes/data/PCRGlobWB20V01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRINT_METADATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUTPATH = \"/volumes/data/temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputLocationSampleGeotiff = \"/volumes/data/PCRGlobWB20V01/additional/sampleGeotiff.tiff\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[xsize,ysize,geotransform,geoproj,ZSample] = readFile(inputLocationSampleGeotiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters of the standard geometry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320 2160 (-179.99999491255934, 0.0833333309780367, 0.0, 90.00000254430942, 0.0, -0.0833333309780367)\n"
     ]
    }
   ],
   "source": [
    "print xsize, ysize, geotransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify if you want to print metadata. This is similar to the previous step and might be redundant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy PLivWN to PLivWW because Livestock Withdrawal = Livestock Consumption (see Yoshi's email'). This will solve some lookping issues in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copies 4GB of data so takes a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWN_month_millionm3_5min_1960_2014.nc4 /volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWW_month_millionm3_5min_1960_2014.nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cp /volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWN_year_millionm3_5min_1960_2014.nc4 /volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWW_year_millionm3_5min_1960_2014.nc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIrrWW_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIrrWN_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWN_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIndUse_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PDomWW_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIndWW_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWW_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWN_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PDomUse_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIndWW_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIndUse_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PDomUse_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIrrWN_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PDomWW_month_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PIrrWW_year_millionm3_5min_1960_2014.nc4\n",
      "/volumes/data/PCRGlobWB20V01/waterdemand/global_historical_PLivWW_year_millionm3_5min_1960_2014.nc4\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(NETCDFINPUTPATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".nc4\"):\n",
    "            oneFile = os.path.join(root, file)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =nc_fid.variables[\"time\"].getncattr(\"units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OUTPUTPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 27",
   "language": "python",
   "name": "python27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
